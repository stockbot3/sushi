<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Sushi - VRM Cinematic Stream</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #010103; color: #fff; overflow: hidden; height: 100vh;
        }
        #root { width: 100%; height: 100%; position: relative; }
        
        .stream-hud {
            position: absolute; top: 0; left: 0; right: 0; z-index: 100;
            background: linear-gradient(180deg, rgba(10,10,15,0.98) 0%, rgba(10,10,15,0.8) 100%);
            border-bottom: 1px solid rgba(255,255,255,0.1);
            backdrop-filter: blur(20px);
        }
        .hud-top { display: flex; align-items: center; justify-content: space-between; padding: 12px 24px; }
        .hud-scores { display: flex; align-items: center; }
        .hud-team { display: flex; align-items: center; gap: 12px; padding: 6px 18px; background: rgba(255,255,255,0.05); border-radius: 12px; }
        .hud-abbr { font-size: 16px; font-weight: 900; letter-spacing: 2px; }
        .hud-pts { font-size: 40px; font-weight: 950; line-height: 1; min-width: 40px; text-align: center; }
        .hud-sep { font-size: 28px; color: rgba(255,255,255,0.15); padding: 0 15px; font-weight: 200; }
        
        .vrm-stage {
            position: absolute; inset: 0; display: flex;
            background: radial-gradient(circle at center, #1a1a2e 0%, #010103 100%);
        }
        .vrm-canvas-container { flex: 1; position: relative; }
        .vrm-canvas { width: 100%; height: 100%; display: block; }

        .subtitle-box {
            position: absolute; bottom: 40px; left: 50%; transform: translateX(-50%);
            width: 90%; max-width: 800px;
            background: rgba(5,5,10,0.9); backdrop-filter: blur(25px);
            padding: 24px 40px; border-radius: 24px;
            border: 1px solid rgba(255,255,255,0.15);
            text-align: center; z-index: 200;
            box-shadow: 0 30px 60px rgba(0,0,0,0.6);
        }
        .subtitle-name { font-size: 13px; font-weight: 900; color: #FFB81C; text-transform: uppercase; margin-bottom: 8px; letter-spacing: 3px; }
        .subtitle-text { font-size: 20px; line-height: 1.6; color: #fff; font-weight: 600; }

        .start-overlay {
            position: fixed; inset: 0; z-index: 500;
            background: rgba(0,0,0,0.95); display: flex; align-items: center; justify-content: center;
            cursor: pointer;
        }
        .start-btn {
            padding: 28px 56px; border-radius: 60px;
            background: #fff; color: #000; font-weight: 900; font-size: 22px;
            box-shadow: 0 20px 50px rgba(255,184,28,0.5);
            letter-spacing: 2px; transition: all 0.3s;
        }
    </style>
</head>
<body>
    <div id="root"></div>
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script type="importmap"> { "imports": { "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js", "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/", "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3/lib/three-vrm.module.min.js" } } </script>
    <script type="module">
        import * as THREE from 'three'; import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js'; import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';
        window.THREE = THREE; window.GLTFLoader = GLTFLoader; window.VRMLoaderPlugin = VRMLoaderPlugin; window.VRMUtils = VRMUtils;
        window.modulesLoaded = true; window.dispatchEvent(new Event('modulesLoaded'));
    </script>
    <script type="text/babel">
        const { useState, useEffect, useRef, useCallback } = React;
        const DEFAULT_SAKURA_URL = 'https://raw.githubusercontent.com/pixiv/three-vrm/release/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm';
        const DEFAULT_YUKI_URL = '/Avatar.vrm';

        const damp = (current, target, lambda, delta) => THREE.MathUtils.damp(current, target, lambda, delta);
        const noise = (t) => Math.sin(t) + Math.sin(t * 2.5) * 0.5;

        const avatarEvents = {
            listeners: [],
            subscribe(fn) { this.listeners.push(fn); return () => { this.listeners = this.listeners.filter(l => l !== fn); }; },
            emit(side, type, data) { this.listeners.forEach(l => l(side, type, data)); }
        };

        class TTSService {
            constructor() { this.audioContext = null; this.isSpeaking = false; }
            async init() {
                if (!this.audioContext) this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                if (this.audioContext.state === 'suspended') await this.audioContext.resume();
                const b = this.audioContext.createBuffer(1, 1, 22050);
                const s = this.audioContext.createBufferSource(); s.buffer = b;
                s.connect(this.audioContext.destination); s.start(0);
            }
            async speak(text, side, voice) {
                if (this.isSpeaking) return; this.isSpeaking = true;
                await this.init();
                try {
                    const res = await fetch('/api/tts', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ text, voice })
                    });
                    const data = await res.json();
                    if (!data.audio) throw new Error();
                    const bin = atob(data.audio);
                    const buf = new Uint8Array(bin.length);
                    for (let i = 0; i < bin.length; i++) buf[i] = bin.charCodeAt(i);
                    const audioBuffer = await this.audioContext.decodeAudioData(buf.buffer);
                    const source = this.audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    const analyser = this.audioContext.createAnalyser();
                    analyser.fftSize = 256; source.connect(analyser); analyser.connect(this.audioContext.destination);
                    const dataArray = new Uint8Array(analyser.frequencyBinCount);
                    const duration = audioBuffer.duration * 1000; const start = Date.now();
                    return new Promise(resolve => {
                        let active = true;
                        const loop = () => {
                            if (!active) return;
                            if (Date.now() - start > duration) { active = false; resolve(); return; }
                            analyser.getByteFrequencyData(dataArray);
                            let avg = 0; for(let i=0; i<dataArray.length; i++) avg += dataArray[i];
                            avg /= dataArray.length;
                            avatarEvents.emit(side, 'viseme', { viseme: avg > 25 ? ['aa','ih','ou','E','oh'][Math.floor(Math.random()*5)] : 'sil', volume: avg/255 });
                            requestAnimationFrame(loop);
                        };
                        source.onended = () => { active = false; this.isSpeaking = false; avatarEvents.emit(side, 'viseme', { viseme: 'sil', volume: 0 }); resolve(); };
                        source.start(0); loop();
                    });
                } catch (e) {
                    this.isSpeaking = false;
                    return new Promise(r => {
                        const u = new SpeechSynthesisUtterance(text);
                        u.onend = r; window.speechSynthesis.speak(u);
                    });
                }
            }
        }

        function Avatar({ side, modelUrl, activeSpeaker }) {
            const canvasRef = useRef(null), vrmRef = useRef(null), speakerRef = useRef(activeSpeaker), isLoadedRef = useRef(false);
            useEffect(() => { speakerRef.current = activeSpeaker; }, [activeSpeaker]);

            useEffect(() => {
                let mounted = true;
                const init = () => {
                    const { THREE, GLTFLoader, VRMLoaderPlugin, VRMUtils } = window;
                    const scene = new THREE.Scene(), cam = new THREE.PerspectiveCamera(30, canvasRef.current.clientWidth / canvasRef.current.clientHeight, 0.1, 1000);
                    cam.position.set(0, 1.35, 2.2); cam.lookAt(0, 1.25, 0);
                    const ren = new THREE.WebGLRenderer({ canvas: canvasRef.current, alpha: true, antialias: true });
                    ren.setSize(canvasRef.current.clientWidth, canvasRef.current.clientHeight); ren.setPixelRatio(window.devicePixelRatio);
                    scene.add(new THREE.AmbientLight(0xffffff, 0.4));
                    const key = new THREE.DirectionalLight(0xffeeb1, 1.5); key.position.set(-1, 2, 3); scene.add(key);
                    const rim = new THREE.DirectionalLight(0x4455ff, 2.0); rim.position.set(2, 2, -2); scene.add(rim);

                    new GLTFLoader().register(p => new VRMLoaderPlugin(p)).load(modelUrl || (side === 'left' ? DEFAULT_SAKURA_URL : DEFAULT_YUKI_URL), gltf => {
                        if (!mounted) return;
                        const vrm = gltf.userData.vrm;
                        if (vrm) {
                            vrmRef.current = vrm; VRMUtils.rotateVRM0(vrm); scene.add(vrm.scene);
                            if (vrm.humanoid) {
                                const l = vrm.humanoid.getNormalizedBoneNode('leftUpperArm'), r = vrm.humanoid.getNormalizedBoneNode('rightUpperArm');
                                if (l) l.rotation.z = -1.35; if (r) r.rotation.z = 1.35;
                            }
                        } else { scene.add(gltf.scene); }
                        isLoadedRef.current = true;
                    });

                    const clock = new THREE.Clock();
                    const animate = () => {
                        if (!mounted) return; requestAnimationFrame(animate);
                        const dt = Math.min(clock.getDelta(), 0.05), time = clock.getElapsedTime();
                        if (vrmRef.current && isLoadedRef.current) {
                            vrmRef.current.update(dt);
                            const h = vrmRef.current.humanoid;
                            if (h) {
                                const spine = h.getNormalizedBoneNode('spine'), head = h.getNormalizedBoneNode('head'), lua = h.getNormalizedBoneNode('leftUpperArm'), rua = h.getNormalizedBoneNode('rightUpperArm'), lla = h.getNormalizedBoneNode('leftLowerArm'), rla = h.getNormalizedBoneNode('rightLowerArm');
                                const isSpeaking = speakerRef.current === side, sway = noise(time * 0.2) * 0.02;
                                if (spine) { spine.rotation.x = damp(spine.rotation.x, isSpeaking ? 0.15 : sway, 2, dt); spine.rotation.y = damp(spine.rotation.y, sway * 0.5, 2, dt); spine.position.y = Math.sin(time * 0.8) * 0.01; }
                                if (head) { const ty = isSpeaking ? 0 : (side === 'left' ? 0.3 : -0.3); const tx = isSpeaking ? Math.sin(time * 2) * 0.05 : 0; head.rotation.y = damp(head.rotation.y, ty + sway, 3, dt); head.rotation.x = damp(head.rotation.x, tx, 5, dt); }
                                let lz = -1.35, rz = 1.35, lx = 0, rx = 0, llx = -0.1, rlx = -0.1;
                                if (isSpeaking) { const g = noise(time * 1.5); lz = -1.1 + g * 0.1; rz = 1.1 - g * 0.1; lx = -0.4 + g * 0.2; rx = -0.4 + g * 0.2; llx = -0.8 + g * 0.3; rlx = -0.8 + g * 0.3; }
                                if (lua) { lua.rotation.z = damp(lua.rotation.z, lz, 4, dt); lua.rotation.x = damp(lua.rotation.x, lx, 4, dt); }
                                if (rua) { rua.rotation.z = damp(rua.rotation.z, rz, 4, dt); rua.rotation.x = damp(rua.rotation.x, rx, 4, dt); }
                                if (lla) lla.rotation.x = damp(lla.rotation.x, llx, 4, dt); if (rla) rla.rotation.x = damp(rla.rotation.x, rlx, 4, dt);
                            }
                            const m = vrmRef.current.expressionManager;
                            if (m && Math.random() < 0.005) { m.setValue('blink', 1); setTimeout(() => m.setValue('blink', 0), 150); }
                        }
                        ren.render(scene, cam);
                    };
                    animate();
                };
                if (window.modulesLoaded) init(); else window.addEventListener('modulesLoaded', init);
                return () => mounted = false;
            }, [side, modelUrl]);

            useEffect(() => {
                return avatarEvents.subscribe((targetSide, type, data) => {
                    if (targetSide !== side || !vrmRef.current?.expressionManager) return;
                    const m = vrmRef.current.expressionManager, map = m._expressionMap;
                    if (type === 'viseme') {
                        ['aa','ih','ou','E','oh','a','i','u','e','o'].forEach(v => { if (v in map) m.setValue(v, 0); });
                        if (data.viseme !== 'sil') {
                            let t = data.viseme;
                            if (!(t in map)) { const f = { 'aa':'a','ih':'i','ou':'u','E':'e','oh':'o' }; t = f[data.viseme] || data.viseme[0].toLowerCase(); }
                            if (!(t in map)) t = t.toUpperCase();
                            if (t in map) m.setValue(t, data.volume * 2.0);
                        }
                        m.update();
                    }
                });
            }, [side]);

            return <div className="vrm-canvas-container"><canvas ref={canvasRef} className="vrm-canvas" /></div>;
        }

        function App() {
            const [started, setStarted] = useState(false), [game, setGame] = useState(null), [commentary, setCommentary] = useState(null);
            const [activeSpeaker, setActiveSpeaker] = useState(null), [sub, setSub] = useState({ name: "", text: "" });
            const [sessionMeta, setSessionMeta] = useState(null);
            const voiceRef = useRef(new TTSService()), queueRef = useRef([]), isProcessingRef = useRef(false), voicedRef = useRef(new Set()), lastSeqRef = useRef(-1);

            useEffect(() => {
                const sid = new URLSearchParams(window.location.search).get('session');
                if (!started || !sid) return;
                fetch('/api/sessions').then(r => r.json()).then(sessions => {
                    const s = sessions.find(s => s.id === sid); if (s) setSessionMeta(s);
                });
                const poll = async () => {
                    try {
                        const [g, c] = await Promise.all([ fetch(`/api/sessions/${sid}/game`).then(r => r.json()), fetch(`/api/sessions/${sid}/commentary/latest`).then(r => r.json()) ]);
                        setGame(g);
                        const seq = c.timestamp;
                        if (seq !== lastSeqRef.current) {
                            lastSeqRef.current = seq;
                            setCommentary(c); queueRef.current = [...c.turns];
                            processQueue();
                        }
                    } catch (e) {}
                };
                poll(); const itv = setInterval(poll, 8000); return () => clearInterval(itv);
            }, [started]);

            const processQueue = async () => {
                if (isProcessingRef.current || queueRef.current.length === 0) return;
                isProcessingRef.current = true;
                while (queueRef.current.length > 0) {
                    const t = queueRef.current.shift();
                    const side = t.speaker === 'A' ? 'left' : 'right';
                    const cMeta = sessionMeta?.commentators?.[t.speaker === 'A' ? 0 : 1];
                    // Correcting voice assignment: A=Female(Sakura)=Amy, B=Male(Avatar.vrm)=Bryce
                    const defaultVoice = side === 'left' ? 'amy' : 'bryce';
                    setSub({ name: t.name, text: t.text }); setActiveSpeaker(side);
                    await voiceRef.current.speak(t.text, side, cMeta?.voice || defaultVoice);
                    setActiveSpeaker(null); setSub({ name: "", text: "" });
                    await new Promise(r => setTimeout(r, 1000));
                }
                isProcessingRef.current = false;
            };

            if (!started) return <div className="start-overlay" onClick={async () => { await voiceRef.current.init(); setStarted(true); }}><div className="start-btn">TAP TO ENTER STREAM</div></div>;

            const cA = sessionMeta?.commentators?.[0], cB = sessionMeta?.commentators?.[1];
            return (
                <div id="root">
                    <div className="stream-hud">
                        <div className="hud-top">
                            <div className="hud-scores">
                                <div className="hud-team"><span className="hud-abbr" style={{color: game?.away?.color}}>{game?.away?.abbreviation}</span><span className="hud-pts">{game?.away?.score}</span></div>
                                <span className="hud-sep">:</span>
                                <div className="hud-team"><span className="hud-pts">{game?.home?.score}</span><span className="hud-abbr" style={{color: game?.home?.color}}>{game?.home?.abbreviation}</span></div>
                            </div>
                        </div>
                    </div>
                    <div className="vrm-stage">
                        <Avatar side="left" modelUrl={cA?.avatarUrl} activeSpeaker={activeSpeaker} />
                        <Avatar side="right" modelUrl={cB?.avatarUrl} activeSpeaker={activeSpeaker} />
                    </div>
                    {sub.text && ( <div className="subtitle-box"> <div className="subtitle-name">{sub.name}</div> <div className="subtitle-text">{sub.text}</div> </div> )}
                </div>
            );
        }
        ReactDOM.createRoot(document.getElementById('root')).render(<App />);
    </script>
</body>
</html>
